# Антонова Татьяна 
# Лабораторная работа 6, вариант 2

# Загрузка библиотек
library(caret)
library(dplyr)
library(ggplot2)

        # Шаг 1: Загрузка данных и предварительная обработка
data <- read.csv("/Users/tatyana/Downloads/hyundi.csv")

# Исключение строк с пропущенными значениями
data <- na.omit(data)

# Проверка структуры данных
str(data)

        # Шаг 2. Создание 6 моделей линейной регрессии
# Функция нормализации
normalize <- function(vector) {
  return((vector - min(vector)) / (max(vector) - min(vector)))
}

# Модель 1: Нормализация и кодирование 
data_model <- data %>%
  mutate(across(where(is.numeric), normalize)) %>%
  mutate(across(where(is.character), ~ as.numeric(as.factor(.))))

model_1 <- lm(price ~ ., data = data_model)
summary(model_1) #Модель model

        # Выводы 
    # 1. Residuals:
#Минимальное значение: -0.07854, Максимальное значение: 0.93003, 1-й квартиль (25-й перцентиль): -0.02211, 
#Медиана: -0.00742, 3-й квартиль (75-й перцентиль): 0.01320
#Эти значения показывают, что остатки распределены довольно симметрично вокруг нуля, хотя может наблюдаться небольшой сдвиг в положительную сторону.

    #2. Коэффициенты:
# (Intercept): интерцепт модели равен -0.1505934. Это значение представляет собой предсказанное значение price, когда все 
#остальные переменные равны нулю (хотя на практике такие условия могут не существовать).
# Значения коэффициентов: 
# - model, year, transmission, mileage, fuelType, mpg, и engineSize имеют высокую статистическую значимость (p-value < 0.001), 
#что указывает на то, что их влияние на ценность автомобиля статистически значимо.
# - tax имеет p-value равный 0.105, что говорит о том, что его влияние не является статистически значимым на уровне 0.05.

        #3. Статистика коэффициентов:
# - t-значения: Для большинства предикторов t-значение велико (больше 2 или меньше -2), что также подтверждает их значимость.
# Например, engineSize имеет t-значение 26.215, что говорит о сильном положительном влиянии этого предиктора на цену: 
#увеличение размера двигателя на 1 ед. ведет к увеличению цены на 0.1606814.

        #4. Оценка качества модели:
#  - Residual standard error (резидульная стандартная ошибка): 0.03483, что указывает на среднюю ошибку предсказания цен.
#  - Multiple R-squared(множественный R-квадрат): 0.722, что говорит о том, что 72.2% изменчивости цен объясняется моделью. 
#  - Adjusted R-squared(скорректированный R-квадрат): 0.7216 учитывает количество предикторов в модели и показывает, 
#что модель достаточно хорошо справляется с объяснением.
#  - F-statistic: 1575 с p-value < 2.2e-16 указывает на то, что как минимум один из предикторов связан с ценой автомобиля.

#------------------------------------------------------------------------------------

#Multiple R-squared (коэффициент детерминации) — это статистическая мера, которая показывает, насколько хорошо модель 
#регрессии подходит наблюдаемым данным. Она определяет долю вариации зависимой переменной, которую можно объяснить 
#независимыми переменными, включёнными в модель. Проще говоря, Multiple R-squared указывает, насколько хорошо модель (1-(SSE/SST)), SSE - сум-а квадратов ошибок, SST-общая сумма квадратов
#предсказывает зависимую переменную на основе предикторов.

#Adjusted R-squared — это более уточнённая версия R-квадрата, которая учитывает количество предикторов в модели и их значимость. 
#В то время как R-квадрат всегда увеличивается при добавлении предикторов, Adjusted R-squared увеличивается только если 
#новые предиктора действительно улучшают модель. Он предотвращает переобучение, балансируя производительность модели с её сложностью

#Residual standard error (RSE) — это метрика, используемая для оценки качества регрессионной модели. Она измеряет 
#среднее расстояние между наблюдаемыми значениями и предсказанными значениями. 
#RSE указывает на то, насколько хорошо модель способна объяснить вариацию в данных. Чем ниже RSE, тем лучше модель 
#предсказывает данные. Более высокое значение предполагает необходимость доработки модели

#F-статистика представляет собой отношение объяснённой суммы квадратов (в расчёте на одну независимую переменную) к остаточной сумме квадратов (в расчёте на одну степень свободы). 
#Формула расчёта: f = MSR / MSE, MSR — это средняя сумма квадратов регрессии, а MSE — средняя квадратная ошибка

#P-значение (p-value) — одна из ключевых величин, используемых в статистике при тестировании гипотез. Она показывает вероятность 
#получения наблюдаемых результатов при условии, что нулевая гипотеза верна, или вероятность ошибки в случае отклонения нулевой гипотезы.

#----------------------------------------------------------------------------------------------------------------

# Модель 2: One Hot Encoding
dummies <- dummyVars(price ~ ., data = data)
data_O_H_encoded <- predict(dummies, newdata = data) %>%
  data.frame()

# Добавляем переменную price обратно в закодированный датафрейм
data_O_H_encoded$price <- data$price

# Создаем модель 2 с обновленным датафреймом
model_2 <- lm(price ~ ., data = data_O_H_encoded)

summary(model_2) # Модель model_O_H_encoded

        #Выводы 
#Качество модели
# - Residual Standard Error: 2367, указывающий на среднюю величину отклонения предсказаний модели от фактических значений. 
#Это значение указывает, что предсказания модели в среднем отклоняются на 2367 от реальных цен.

# - R-squared: 0.8448, что означает, что 84.48% изменчивости цен на автомобили объясняется независимыми переменными в модели. 
#Это довольно высокий индекс, что указывает на хорошую предсказательную способность модели.

# - Adjusted R-squared: 0.844, что также подтверждает, что модель учитывает число параметров и не введена чрезмерная оптимизация.

# - F-statistic: 1012 с p-value < 2.2e-16, что указывает на то, что, в целом, модель объясняет значительную часть вариации в 
#зависимой переменной (цене автомобилей).

#Высокий R-squared и значимость p-значений подтверждают, что модель достаточно хороша, чтобы делать предсказания 
#относительно цен на автомобили, основываясь на использованных признаках.

# Модель 3: Логарифмирование отклика
data_log_response <- predict(dummies, newdata = data) %>%
  data.frame() %>%
  mutate(across(where(is.numeric), normalize))

data_log_response$price <- log(data$price)
model_3 <- lm(price ~ ., data = data_log_response)

summary(model_3) # Модель model_log_response

        #Выводы 
    # Качество модели

#- Residual Standard Error: 0.1164, указывающий на небольшую среднюю величину отклонения предсказаний от реальных 
#значений после логарифмирования цены.
# - R-squared: 0.9369, что означает, что модель объясняет 93.69% вариации цен на автомобили. Это очень высокий показатель.
# - Adjusted R-squared: 0.9365, подтверждает, что модель имеет хорошую предсказательную способность,
#даже учитывая количество использованных переменных.

    # Другие наблюдения
# Значительное количество переменных с NA указывает на проблемы с многоколлинеарностью (сингульные переменные)
# Модель продемонстрировала отличные характеристики предсказания цены на автомобили, что делает ее пригодной для использования в практикe


# Модель 4: Извлечение квадратного корня отклика
data_sqrt_response <- predict(dummies, newdata = data) %>%
  data.frame() %>%
  mutate(across(where(is.numeric), normalize))

data_sqrt_response$price <- sqrt(data$price)
model_4 <- lm(price ~ ., data = data_sqrt_response)

summary(model_4) # Модель model_sqrt_response

        #Выводы 
    # Качество модели
# - Residual Standard Error: 7.618, что указывает на среднее отклонение предсказаний от реальных значений.
# - R-squared: 0.909, что означает, что модель объясняет 90.9% вариации цен на автомобили, что является высоким показателем 
#для предсказательной модели.
# - Adjusted R-squared: 0.9085, что подтверждает хорошую адаптацию модели с учетом числа переменных.

    # Другие наблюдения
# Наличие NA указывает на возможные проблемы с многоколлинеарностью (сингульные переменные), которые могут потребоваться 
#дополнительной обработки или исключения.
# Высокие значения p для некоторых моделей и фактов подтверждают необходимость дальнейшего анализа и возможных корректировок в модели.

#Эти выводы указывают на то, что модель model_4, использующая квадратный корень цены, демонстрирует отличные характеристики 
#предсказания и позволяет оценивать влияние различных факторов на цены автомобилей.

# Модель 5: Преобразованный предиктор
data_transformed_feature <- predict(dummies, newdata = data) %>%
  data.frame() %>%
  mutate(across(where(is.numeric), normalize))

# Добавление переменной price в новый датафрейм
data_transformed_feature$price <- data$price

# Преобразование переменной engineSize
data_transformed_feature$engineSize_sqrt <- sqrt(data$engineSize)

# Построение модели
model_5 <- lm(price ~ ., data = data_transformed_feature)

summary(model_5) # Модель model_transformed_feature 

        #Выводы 
    # Качество модели
#- Residual Standard Error: 2304, указывающий на среднее отклонение предсказаний от реальных значений, достаточно высокое значение.
#- R-squared: 0.853, это означает, что модель объясняет 85.3% вариации цен на автомобили, что указывает на хорошую, но
#не идеальную предсказательную способность.
#- Adjusted R-squared: 0.8522, что подтверждает, что модель имеет адекватную предсказательную способность, учитывая количество переменных.

    # Другие наблюдения
# Наличие NA указывает на проблемы с многоколлинеарностью (сингульные переменные), 
#что может требовать дополнительного анализа или исключения некоторых переменных из модели.
#В целом, модель показывает хорошие характеристики, хотя высокий уровень стандартной ошибки остатков и наличие NA 
#на некоторые переменные указывают на возможные недостатки, которые могут быть устранены в будущих итерациях модели.

# Модель 6: Логарифмирование отклика + преобразованный предиктор
data_log_response_transformed <- data_O_H_encoded %>%
  mutate(price = log(price),
         engineSize_sqrt = sqrt(data$engineSize))

model_6 <- lm(price ~ ., data = data_log_response_transformed)

summary(model_6) # Модель model_log_response_transformed_feature

        #Выводы
    # Качество модели
# - Residual Standard Error: 0.111, что указывает на небольшое среднее отклонение предсказаний от фактических 
#значений, подтверждая высокую точность модели.
# - R-squared: 0.9425, что означает, что модель объясняет 94.25% вариации логарифма цен на автомобили, 
#что является отличным показателем для предсказательной модели.
# - Adjusted R-squared: 0.9422, что также подтверждает, что модель имеет хорошую предсказательную способность с учетом количества переменных.

    # Другие наблюдения
# Наличие NA для некоторых переменных указывает на проблемы с многоколлинеарностью
# В целом, модель показывает отличные характеристики и высокая значимость множества предикторов говорит о 
#наличии полезной информации для предсказания цен на автомобили.

# Шаг 3. Визуальный анализ выполнения допущений модели 
# Создание функции для построения всех 4 графиков для одной модели
plot_model_diagnostics <- function(model, model_name) { 
  par(mfrow = c(2, 2)) # Разделяем окно на 2 строки и 2 столбца
  
  # 1. График остатков против предсказ-х значений
  plot(fitted(model), residuals(model),
       xlab = "Предсказанные значения",
       ylab = "Остатки",
       main = paste("Остатки против предсказ-х зн-й для", model_name))
  abline(h = 0, col = "red") 
  
  # 2. QQ-plot для остатков
  qqnorm(residuals(model), main = paste("QQ-plot для", model_name))
  qqline(residuals(model), col = "red")
  
  # 3. График стьюдентизированных остатков
  std_residuals <- rstandard(model) 
  plot(fitted(model), std_residuals,
       xlab = "Предсказанные значения",
       ylab = "Стьюдентизированные остатки",
       main = paste("Стьюдентизированные остатки для", model_name))
  abline(h = c(-3, 3), col = "red", lty = 2) 
  
  # 4. График остатков против показателя расбалансировки (leverage)
  leverage <- hatvalues(model) 
  plot(leverage, residuals(model),
       xlab = "Leverage",
       ylab = "Остатки",
       main = paste("Остатки против Leverage для", model_name))
  abline(h = 0, col = "red") 
  abline(v = 0.5, col = "blue", lty = 2) # линии Кука на уровне 0.5
}

# Применение функции для каждой модели отдельно
plot_model_diagnostics(model_1, "М_1")
plot_model_diagnostics(model_2, "М_2")
plot_model_diagnostics(model_3, "М_3")
plot_model_diagnostics(model_4, "М_4")
plot_model_diagnostics(model_5, "М_5")
plot_model_diagnostics(model_6, "М_6")

#---------------------------------------------------------------------------------------------
#1. Остатки против предсказанных значений (вверху слева): Этот график показывает 
#остатки (разность между фактическими и предсказанными значениями) в зависимости от 
#предсказанных значений. Идеальная модель должна иметь случайное распределение остатков вокруг 
#нуля без видимых шаблонов.

#2. QQ-plot (вверху справа): График Квантиль-квантиль позволяет оценить, насколько остатки модели 
#следуют нормальному распределению. Если остатки находятся на прямой, это указывает на нормальность.

#3. Стьюдентизированные остатки (внизу слева): Этот график аналогичен первому, но показывает 
#стьюдентизированные остатки, которые нормализованы по величине. Это помогает в оценке выбросов.

#4. Остатки против Leverage (внизу справа): Этот график помогает выявить наблюдения с высоким рычагом, 
#которые могут оказывать значительное влияние на параметры модели. Наблюдения с высоким рычагом, в
#сочетании с большими остатками, могут быть выбросами.

        # Шаг 4. Выбор модели
# Данные из summary

#  | Модель   | Residual Standard Error | R-squared | Adjusted R-squared | F-statistic              | p-value                  |
#  |----------|-------------------------|-----------|---------------------|--------------------------|--------------------------|
#  | Модель 1 | 0.03483                 | 0.722     | 0.7216              | 1575                     | < 2.2e-16                |
#  | Модель 2 | 2367                    | 0.8448    | 0.844               | 1012                     | < 2.2e-16                |
#  | Модель 3 | 0.1164                  | 0.9369    | 0.9365              | 2759 (DF: 26, 4833)      | < 2.2e-16                |
#  | Модель 4 | 7.618                   | 0.909     | 0.9085              | 1857 (DF: 26, 4833)      | < 2.2e-16                |
#  | Модель 5 | 2304                    | 0.853     | 0.8522              | 1038 (DF: 27, 4832)      | < 2.2e-16                |
#  | Модель 6 | 0.111                   | 0.9425    | 0.9422              | 2935 (DF: 27, 4832)      | < 2.2e-16                |
  
  
# Анализ

#1. Residual Standard Error (RSE):
#   Модели 1, 3 и 6 имеют значительно меньшие значения RSE, что указывает на более высокую точность предсказаний.
# Модель 6 имеет наименьшую RSE (0.111) среди всех, что подтверждает ее высокое качество предсказания.

#2. R-squared и Adjusted R-squared:
#   Модель 6 показывает самое высокое значение R^2 (0.9425), за ней следует модель 3 (0.9369). Это указывает 
#на то, что обе модели хорошо объясняют вариацию в данных.
# Модель 1 имеет самое низкое значение R^2 (0.722), что указывает на то, что она наименее адекватно описывает зависимость от переменных.

#3. F-statistic и p-value:
# Все модели показывают высокие значения F-статистики, что указывает на значительность моделей.
# Модель 6 имеет наивысшую F-статистику (2935), что сигнализирует о ее лучшей общей значимости по сравнению с другими.

#4. Сравнение по другим метрикам:
#  Модели 2, 4 и 5 имеют более высокие RSE по сравнению с моделями 3 и 6, что предполагает их меньшую точность в предсказаниях.
#  Модель 4 показывает R^2 (0.909) и скорректированный R^2 (0.9085), но все же уступает по точности моделям 3 и 6.

# Заключение
#На основании всех данных, Модель 6 является наиболее адекватной для предсказания цены автомобиля. Она демонстрирует наименьшую 
#стандартную ошибку остатков, наивысшие значения R^2 и скорректированного R^2, а также наивысшую F-статистику, что подтверждает
#значимость модели. Модель 3 также показывает отличные результаты и стоит рассматривать как альтернативу, если это необходимо. 


        # Шаг 5. Прогнозирование цены автомобиля с произвольными значениями признаков
# Задаем произвольные значения для признаков

summary(model_6)

# В выводе функции summary(model_6) для переменных model.Veloster, transmissionSemi.Auto и fuelTypePetrol 
#есть значения NA, это говорит о том, что эти переменные линейно зависимы от других переменных в модели. 
#Следовательно, их необходимо удалить из модели.

#1. Удаление затрудняющих переменных:
# Чтобы устранить проблему, удалим упомянутые переменные из модели
model_6 <- lm(price ~ year + transmissionAutomatic + transmissionManual + 
                mileage + fuelTypeDiesel + fuelTypeHybrid + 
                fuelTypeOther + mpg + engineSize + engineSize_sqrt,
              data = data_log_response_transformed)

summary(model_6)  # Чтобы проверить, есть ли еще NA

#2. Задаем произвольные значения для признаков
new_data <- data.frame(
  model.Accent = 0,
  model.Amica = 0,
  model.Getz = 0,
  model.I10 = 0,
  model.I20 = 0,
  model.I30 = 0,
  model.I40 = 0,
  model.I800 = 0,
  model.Ioniq = 0,
  model.IX20 = 0,
  model.IX35 = 0,
  model.Kona = 0,
  model.Santa.Fe = 0,
  model.Terracan = 0,
  model.Tucson = 0,
  year = 2020,
  transmissionAutomatic = 0,
  transmissionManual = 1,
  mileage = 15000,
  fuelTypeDiesel = 0,
  fuelTypeHybrid = 0,
  fuelTypeOther = 0,
  tax... = 200, 
  mpg = 35,
  engineSize = 1.6,
  engineSize_sqrt = sqrt(1.6)
)

# Прогнозируем цену
predicted_log_price <- predict(model_6, newdata = new_data)

# Преобразуем предсказанную цену обратно из логарифмического формата
predicted_price <- exp(predicted_log_price)

# Выводим предсказанную цену
print(predicted_price)

